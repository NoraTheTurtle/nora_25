{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: Computing Bias lesson\n",
    "description: homework/popcorn hacks\n",
    "layout: post\n",
    "type: hacks\n",
    "comments: true\n",
    "toc: false\n",
    "courses: { compsci: {week: 26} }\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# POPCORN HACKS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Popcorn hack 1\n",
    "\n",
    "**Explicit Data**\n",
    "\n",
    "answer b) providing your name/age is explicit data because the user inputs it\n",
    "\n",
    "### Popcorn hack 2\n",
    "\n",
    "**Data Bias**\n",
    "\n",
    "answer b) AI trained from a dataset of only specific groups is biased, leaving the minoritys unrepresented\n",
    "\n",
    "### Popcorn hack 3\n",
    "\n",
    "**Unintentional Bias**\n",
    "\n",
    "ex: Another example is in hiring algorithms. Some companies use AI to screen job applicants, but if the training data comes from past hiring decisions that favored men over women, the AI may learn to prefer male candidates, even if gender is not an explicit input. This is unintentional biasâ€”the AI picks up on patterns in the data that reflect historical discrimination.\n",
    "\n",
    "This is unintentional bias by the computer because of the data it was given"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
